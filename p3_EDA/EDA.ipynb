{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a4f1316-6c26-4ec8-81cb-d1db44eac0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, subprocess\n",
    "from IPython.display import Video, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21c4de6c-8225-4b58-a2e8-5276e83cbed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vidFilePaths = ['../datasrc/fundus-oct-composite/Healthy/P_12/Left_Eye/2d_lt.wmv',\n",
    " '../datasrc/fundus-oct-composite/Healthy/P_12/Right_Eye/2d_rt.wmv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "161b8d9a-4f14-4ec6-b92b-174eab6e41e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"/tmp/2d_lt_temp.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def displayWMV(wmvPath):\n",
    "\n",
    "    filename = os.path.basename(wmvPath)\n",
    "    # oDIR = os.path.dirname(wmvPath)\n",
    "    # Convert wmv files to mp4 to be viewed in jupyter\n",
    "    oPATH = os.path.join('/tmp',f'{filename.split(\".\")[0]}_temp.mp4')\n",
    "    subprocess.run([\"ffmpeg\",\"-loglevel\",\"error\", \"-i\", wmvPath, oPATH, \"-y\"])\n",
    "    video = Video(oPATH)\n",
    "    display(video)\n",
    "\n",
    "displayWMV(vidFilePaths[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26d160b-72a7-4f4e-981b-de272162ce7e",
   "metadata": {},
   "source": [
    "While this suggests the possibility reconstructing a volume from the frames (particularly since they go from index 0 to 127, therefore contributing to a width of 128px in that dimension, and can be downsampled to 64px in that dimension to match that of the volumes in the other set), there are only two videos in the entire set, it seems, and would contribute two healthy volumes for a single patient (OS/OD).  Unlikely to be of much use here, but can get back to it later if desired.  Now, back to extracting tabular data from the paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684c20eb-bc8b-48ec-986a-a5e17d1b55ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def InputImageStandardizer(imageInput):\n",
    "    '''Converts various forms of input for an image to a numpy array, including:\n",
    "        1. Image object (NumPy array in memory / assigned to a variable) - no change\n",
    "        2. Path to image file - should be compatible with `cv2.imread()` if possible \n",
    "            (e.g., '.jpg','.png','.jpeg')\n",
    "        3. Path to a NumPy array file (`.npy`) - will read using `numpy.load()`\n",
    "    '''\n",
    "\n",
    "    # If the input is already a NumPy array, no change is needed\n",
    "    if type(imageInput) == np.ndarray:\n",
    "        imageArray = imageInput\n",
    "\n",
    "    # If the input is a string, it may be a path to an image or a path to a NumPy array\n",
    "    elif type(imageInput) == str:\n",
    "        try:\n",
    "            # Make the path exists and is a file\n",
    "            if os.path.isfile(imageInput):\n",
    "                # Check if the file is a conventional image file\n",
    "                magicReport = magic.from_file(imageInput)\n",
    "                if 'image' in magicReport:\n",
    "                    # Try first to read the image using `cv2.imread()` - should work for most images\n",
    "                    try:\n",
    "                        imageArray = cv2.imread(imageInput)\n",
    "                    except:\n",
    "                        # If that fails, try to read the image using `cv2.imdecode()`\n",
    "                        #  -  this may work for certain image types not supported by `cv2.imread()`\n",
    "                        #  -  e.g., certain forms of TIFF, BMP, etc.\n",
    "                        try:\n",
    "                            imageArray = cv2.imdecode(np.fromfile(imageInput,dtype=np.uint8),cv2.IMREAD_COLOR)\n",
    "                        except:\n",
    "                            raise ValueError(f'Image format not supported: {magicReport}')\n",
    "                    \n",
    "                    # Since `cv2.imread()` and `cv2.imdecode()` return images in BGR format, convert to RGB for compatibility with plt.imshow()\n",
    "                    imageArray = cv2.cvtColor(imageArray,cv2.COLOR_BGR2RGB)\n",
    "\n",
    "                # If the image file is in the form of a NumPy array file, read using `numpy.load()`\n",
    "                elif magicReport.startswith('NumPy array'):\n",
    "                    imageArray = np.load(imageInput)\n",
    "                else:\n",
    "                    raise ValueError(f'Image format not supported: {magicReport}')\n",
    "            else:\n",
    "                raise ValueError(f'Path is not a file: {imageInput}')\n",
    "        except:\n",
    "            raise ValueError(f'Invalid image path: {imageInput}')                            \n",
    "    else:\n",
    "        raise ValueError(f'Input type not supported: {type(imageInput)} -- skipping...')\n",
    "    \n",
    "    return imageArray\n",
    "\n",
    "def imPanelShow(images:list, image_names:list=None, ncols=2, figsize=(10,10)):\n",
    "    '''Displays a panel of images in a figure, with each image in a separate subplot.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    images : list\n",
    "        List of image paths or image arrays to be displayed in the panel.\n",
    "\n",
    "    image_names : list, optional\n",
    "        List of image names corresponding to the images, by default None\n",
    "        If `images` is a list of paths, then the image names will be extracted from the paths.\n",
    "        Otherwise, the image names will be the indices of the images in the list if `image_names` is not provided.\n",
    "\n",
    "    ncols : int, optional\n",
    "        Number of columns in the panel, by default 2\n",
    "\n",
    "    figsize : tuple, optional\n",
    "        Figure size, by default (10,10)\n",
    "    \n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    fig : matplotlib.figure.Figure\n",
    "        Figure object containing the panel of images.\n",
    "    ax : matplotlib.axes.Axes\n",
    "        Axes object containing the panel of images.\n",
    "    '''\n",
    "    \n",
    "    # Standardize the input images list to a list of NumPy arrays\n",
    "    imageArrays = [ InputImageStandardizer(i) for i in images ]\n",
    "\n",
    "    # If no image names are provided, use the indices of the images in the list\n",
    "    # if image_names is None:\n",
    "    #     images = [str(i) for i in range(len(imageArrays))]\n",
    "    # else:\n",
    "    #     images = image_names\n",
    "\n",
    "    # Determine the number of rows based on the number of images and specified number of columns (default is 2)\n",
    "    # nrows = int(math.ceil(len(imageArrays)/ncols))\n",
    "    nrows = len(imageArrays) // ncols\n",
    "    if len(imageArrays) % 2 != 0:\n",
    "        nrows += 1\n",
    "\n",
    "    \n",
    "    _,ax = plt.subplots(nrows,ncols,figsize=figsize)\n",
    "    \n",
    "    for i,img in enumerate(imageArrays):\n",
    "\n",
    "        ax.flat[i].imshow(img)\n",
    "        \n",
    "        # If the image is a path, extract the image name from the path\n",
    "        if type(images[i]) == str:\n",
    "            title = os.path.basename(images[i])\n",
    "        # Otherwise (i.e., if the image is a NumPy array)\n",
    "        # If image names are provided, use those\n",
    "        elif image_names is not None:\n",
    "            title = os.path.basename(image_names[i])\n",
    "        # If no image names are provided, use the indices of the images in the list as suffix\n",
    "        else:\n",
    "            title = f\"image_{i}\"\n",
    "            \n",
    "        ax.flat[i].set_title(title,fontsize=9)\n",
    "    \n",
    "    plt.subplots_adjust(hspace=.4)\n",
    "        \n",
    "# imPanelShow(sampleImgPaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0b2769-9aa1-444e-be7c-e3be7e1ceba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "bscans = [cv2.imread(i) for i in oct2D[oct2D['b-scan']]['filepath']]\n",
    "bscans[0].shape\n",
    "\n",
    "# lambda function to return the filepaths for a given patient ID number (i.e., the # in the P_# format)\n",
    "ptscans = lambda i : oct2D[oct2D.pid.str.endswith(f\"_{i}\")]['filepath'].values\n",
    "\n",
    "imPanelShow(ptscans(1),figsize=(10,5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9df2353-75b2-4fd9-bf9e-072d8fc37b57",
   "metadata": {},
   "source": [
    "#### Identifying Shaded Region Boundaries via Color Transition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdc274b-9116-4fdf-9a12-f241b1eaa832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the image is in BGR format, convert to RGB for compatibility with plt.imshow()\n",
    "img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "\n",
    "blue = img[:, :, 2].mean(axis=0)\n",
    "green = img[:, :, 1].mean(axis=0)\n",
    "red = img[:, :, 0].mean(axis=0)\n",
    "\n",
    "fig,ax = plt.subplots(1,2,figsize=(12,3))\n",
    "fig.suptitle(ptscans(2)[1])\n",
    "ax.flat[0].imshow(img)\n",
    "ax.flat[0].set_title(f'Original Image',fontsize=10)\n",
    "\n",
    "ax.flat[1].plot(red,c='red')\n",
    "ax.flat[1].plot(blue)\n",
    "ax.flat[1].plot(green,c='green')\n",
    "ax.flat[1].set_title(f'RGB Means',fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22951349-8242-41af-aac3-846f00fa285a",
   "metadata": {},
   "source": [
    "#### Cropping Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0776870-f659-4363-8f43-a76c2dcc1b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_b = 50\n",
    "threshold_g = 50\n",
    "threshold_r = 50\n",
    "\n",
    "shaded_cols = np.where((blue > threshold_b) & (green < threshold_g) & (red < threshold_r))[0]\n",
    "\n",
    "imgCR1 = img[:,shaded_cols,:]\n",
    "\n",
    "imgCR1 = cv2.cvtColor(imgCR1,cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.imshow(imgCR1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e65c6a-56e8-4b4c-93b0-dd44369677ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cropBSCAN(img,BGRthresh=(50,50,50),explore=False,showMode=None):\n",
    "\n",
    "    if os.path.isfile(img):\n",
    "        img = cv2.imread(img)\n",
    "\n",
    "    # Crop out bottom scalebar\n",
    "    row_scores = np.abs(np.diff(img.astype(int),axis=0)).mean(axis=(1,2))\n",
    "    indices = np.where(row_scores[::-1] > 50)[0]\n",
    "    top_of_band = img.shape[0] - indices.max() - 1\n",
    "    imgbc = img[:top_of_band,:,:]\n",
    "\n",
    "    # Crop out sides based on color transition\n",
    "    blue = imgbc[:, :, 2].mean(axis=0)\n",
    "    green = imgbc[:, :, 1].mean(axis=0)\n",
    "    red = imgbc[:, :, 0].mean(axis=0)\n",
    "    \n",
    "    if explore:\n",
    "        plt.plot(red,c='red')\n",
    "        plt.plot(blue,c='blue')\n",
    "        plt.plot(green,c='green')\n",
    "    else:\n",
    "        threshold_b, threshold_g, threshold_r = BGRthresh\n",
    "        shaded_cols = np.where((blue > threshold_b) & (green < threshold_g) & (red < threshold_r))[0]\n",
    "        cropped_image = imgbc[:,shaded_cols,:]\n",
    "        if showMode == 'compare':\n",
    "            fig,(l,r) = plt.subplots(1,2,figsize=(8,8))\n",
    "            l.imshow(cropped_image)\n",
    "            r.imshow(img)\n",
    "        elif showMode == 'result':\n",
    "            plt.imshow(cropped_image)\n",
    "        else:\n",
    "            return cropped_image\n",
    "\n",
    "cropBSCAN(ptscans(11)[0],showMode='compare')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e849827-2d22-4408-89fa-4385f5548299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not all images had shaded ONH / optic disc regions, so remove those for now\n",
    "bscanCroppables = [ i for i in bscanCROPPED if i.shape[1] > 0]\n",
    "len(bscanCroppables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34439134-70a3-462c-89e7-2eecd09b1fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "meanWidth = np.array([ i.shape[1] for i in bscanCroppables ]).mean().astype(int)\n",
    "meanHeight = np.array([ i.shape[0] for i in bscanCroppables ]).mean().astype(int)\n",
    "meanAR = (meanWidth / meanHeight).round(3)\n",
    "from fractions import Fraction\n",
    "print(f'Mean width: {meanWidth}')\n",
    "print(f'Mean height: {meanHeight}')\n",
    "print(f'Mean AR: {meanAR} ({Fraction(meanAR).limit_denominator()})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb74a06-7c56-40b7-aec2-909474d255a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize2Dimage(imgArray, preview=True):\n",
    "    \n",
    "\n",
    "    # crop to AR of 1:2 (width:height)\n",
    "    height, width = imgArray.shape[:2]\n",
    "    aspect_ratio = width / height\n",
    "\n",
    "    # Determine which axis is too long\n",
    "    if aspect_ratio > 0.5:  # width is too long\n",
    "        # Calculate the amount of pixels to shave off from both sides\n",
    "        shave_pixels = int((width - 0.5 * height) / 2)\n",
    "        # Crop the image\n",
    "        iarNorm = imgArray[:, shave_pixels:-shave_pixels, :]\n",
    "    else:  # height is too long\n",
    "        # Calculate the amount of pixels to shave off from both sides\n",
    "        shave_pixels = int((height - 2 * width) / 2)\n",
    "        # Crop the image\n",
    "        iarNorm = imgArray[shave_pixels:-shave_pixels, :, :]\n",
    "\n",
    "    \n",
    "    # downsample to 64x128\n",
    "    iarNorm = cv2.resize(iarNorm, (64, 128))\n",
    "\n",
    "    if preview:\n",
    "        print(f\"{shave_pixels} pixels shaved off from each side.\")\n",
    "        fig,ax = plt.subplots(1,2,figsize=(12,12))\n",
    "        ax[0].imshow(imgArray)\n",
    "        ax[0].set_title(f'Original Image {imgArray.shape}',fontsize=10)\n",
    "        ax[1].imshow(iarNorm)\n",
    "        ax[1].set_title(f'Normalized Image {iarNorm.shape}',fontsize=10)\n",
    "       \n",
    "    else:\n",
    "        return iarNorm\n",
    "\n",
    "\n",
    "\n",
    "normalize2Dimage(bscanCroppables[5])\n",
    "\n",
    "normBSCANs = [ normalize2Dimage(i,preview=False) for i in bscanCroppables ]\n",
    "normBSCANs = [ i[:,:,1] for i in normBSCANs ]\n",
    "\n",
    "\n",
    "imPanelShow(normBSCANs[0:20], ncols=5, figsize=(12,12))\n",
    "\n",
    "\n",
    "bcvars = [ cv2.convertScaleAbs(normBSCANs[0],alpha=a,beta=b) for a in np.linspace(0,2,10) for b in np.linspace(0,255,20).astype(int)]\n",
    "\n",
    "len(bcvars)\n",
    "\n",
    "imPanelShow(bcvars[30:45], ncols=5\n",
    "            , figsize=(12,12))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41efd5b2-06e5-44b0-b91b-957fbf480057",
   "metadata": {},
   "source": [
    "Attempted to check image similarity scores to see if cropped images could match up with slices of the volumes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4761d42-d8fd-48b8-8ef5-eb3900fae707",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import metrics\n",
    "\n",
    "ref_image = vol[32,:,:]\n",
    "\n",
    "\n",
    "\n",
    "# Define the similarity metric\n",
    "def similarity_metric(image1, image2):\n",
    "    return metrics.structural_similarity(image1, image2)\n",
    "\n",
    "# Calculate the similarity scores\n",
    "similarity_scores = []\n",
    "for image in bcvars:\n",
    "    score = similarity_metric(ref_image, image)\n",
    "    similarity_scores.append(score)\n",
    "\n",
    "for i,s in enumerate(similarity_scores):\n",
    "    print(f'{i}: {s}')\n",
    "\n",
    "# Find the maximum similarity score\n",
    "max_score_index = np.argmin(similarity_scores)\n",
    "\n",
    "print(f\"\\n\\nMaximum similarity score: {max_score_index} {similarity_scores[max_score_index]}\")\n",
    "\n",
    "plt.imshow(bcvars[90])\n",
    "similarity_scores[90]\n",
    "\n",
    "# # Retrieve the best alpha/beta values\n",
    "# best_alpha = alpha_values[max_score_index // len(beta_values)]\n",
    "# best_beta = beta_values[max_score_index % len(beta_values)]\n",
    "\n",
    "# print(f\"Best alpha/beta values: {best_alpha}, {best_beta}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
